# Bild Prompt for AI Fantasy Draft Assistant

üîß Build Brief: AI Fantasy Draft Assistant (Python + FastAPI + Next.js)

Objective

Build a production-ready AI-assisted fantasy football draft tool that:
	‚Ä¢	Ranks players by custom scoring using last year‚Äôs stats and upcoming projections.
	‚Ä¢	Filters/sorts by position, tiers, ADP, depth charts, injury news, and roster needs.
	‚Ä¢	Tracks an in-person draft (manual picks) or live draft (Sleeper sync).
	‚Ä¢	Provides real-time pick advice with short LLM rationales.
	‚Ä¢	Implements all 4 premium features:
	1.	Monte Carlo season simulations (floor/ceiling, volatility)
	2.	Schedule pockets (startable weeks; early-season usability)
	3.	Exposure control (cap % across multiple leagues)
	4.	Opponent modeling (predict next picks from ADP deltas)

Use FastAPI, PostgreSQL, Redis, and Next.js; containerize with Docker; test with pytest and Playwright; CI via GitHub Actions.

‚∏ª

Repo Layout (create these files)

/fantasy-assistant
  /backend
    app/main.py
    app/api/__init__.py
    app/api/routes_rankings.py
    app/api/routes_draft.py
    app/api/routes_advice.py
    app/core/config.py
    app/core/scoring.py
    app/core/tiers.py
    app/core/vorp.py
    app/core/monte_carlo.py
    app/core/schedule_pockets.py
    app/core/exposure.py
    app/core/opponent_model.py
    app/services/ingest_projections.py
    app/services/ingest_stats_last_year.py
    app/services/ingest_depth.py
    app/services/ingest_injuries.py
    app/services/sleeper_sync.py
    app/services/id_map.py
    app/db/base.py
    app/db/models.py
    app/db/schema_migrations/001_init.sql
    app/workers/scheduler.py
    tests/test_scoring.py
    tests/test_vorp.py
    tests/test_advice.py
    tests/test_monte_carlo.py
    pyproject.toml
    README.md
    .env.example
    Dockerfile
  /frontend
    next.config.js
    package.json
    app/layout.tsx
    app/page.tsx
    app/draft/page.tsx
    app/components/Board.tsx
    app/components/Tiers.tsx
    app/components/Advice.tsx
    app/components/Queue.tsx
    app/components/Filters.tsx
    app/lib/api.ts
    e2e/playwright.config.ts
    e2e/draft.spec.ts
    Dockerfile
  /ops
    docker-compose.yml
    migrate.sh
    seed.sh
  .github/workflows/ci.yml
  LICENSE
  README.md


‚∏ª

Tech & Packages
	‚Ä¢	Backend: FastAPI, pydantic, pandas, numpy, SQLAlchemy, asyncpg, redis, httpx, uvicorn, scikit-learn (for simple models), orjson.
	‚Ä¢	Workers: APScheduler (cron-style jobs).
	‚Ä¢	Monte Carlo: numpy random; percentile summaries.
	‚Ä¢	Frontend: Next.js (App Router), React Server Components, Tailwind, Zustand.
	‚Ä¢	Tests: pytest (unit), Playwright (e2e).
	‚Ä¢	CI: GitHub Actions (lint, type-check, test, container build).

‚∏ª

Environment & Secrets (create .env.example)

POSTGRES_URL=postgresql+asyncpg://postgres:postgres@db:5432/fantasy
REDIS_URL=redis://cache:6379/0
PROJECTIONS_API_KEY=replace_me
INJURIES_API_KEY=replace_me
SLEEPER_LEAGUE_ID=optional_for_live_sync
LLM_API_KEY=replace_me
SCORING_JSON={"pass_yd":0.04,"pass_td":4,"int":-2,"rush_yd":0.1,"rush_td":6,"rec":1,"rec_yd":0.1,"rec_td":6,"fumble":-2}


‚∏ª

Database Schema (create 001_init.sql)
	‚Ä¢	players(id uuid pk, name, team, position, bye_week, age, height, weight, xrefs jsonb, created_at)
	‚Ä¢	projections(id, player_id fk, season int, source text, stats jsonb, updated_at)
	‚Ä¢	historical_stats(id, player_id fk, season int, stats jsonb, updated_at)
	‚Ä¢	depth_charts(id, team, position, player_id fk, rank int, updated_at)
	‚Ä¢	injuries(id, player_id fk, status text, note text, updated_at)
	‚Ä¢	adp(id, player_id fk, platform text, adp numeric, sample_size int, updated_at)
	‚Ä¢	draft_picks(id, league_id text, round int, pick int, player_id fk, team_slot text, ts timestamptz)
	‚Ä¢	user_settings(id, user_id text, scoring jsonb, exposure_limits jsonb, strategy jsonb)
	‚Ä¢	leagues(id, platform text, settings jsonb, scoring jsonb, created_at)
	‚Ä¢	Indices on (position), (team, position, rank), (updated_at), (platform, adp)

‚∏ª

Core Algorithms (backend modules to implement)

1) Scoring & VORP
	‚Ä¢	core/scoring.py: compute fantasy points from projections according to SCORING_JSON.
	‚Ä¢	core/vorp.py: compute baseline by position (QB12/RB24/WR36/TE12 default), set vorp, tier (z-scores with natural gap detection).

2) Advice Engine
	‚Ä¢	Inputs: roster state, ADP, tiers, injuries, depth rank, bye weeks, stacks.
	‚Ä¢	Outputs: top 5 recommendations with reasons + alternatives.
	‚Ä¢	Contextual rules:
	‚Ä¢	Roster construction penalties/bonuses.
	‚Ä¢	ADP drift (prefer value when a player‚Äôs market allows waiting).
	‚Ä¢	Stack bonus (QB + WR/TE from same team).
	‚Ä¢	Injury/doubtful demotion, depth rank >3 demotion.

3) Monte Carlo (Nice-to-Have #1)
	‚Ä¢	For each player, simulate season outcomes using variance parameters per stat.
	‚Ä¢	Return median, p10, p90, volatility score, and boom/bust flags.
	‚Ä¢	Surface ceiling/floor columns in /rankings.

4) Schedule Pockets (Nice-to-Have #2)
	‚Ä¢	Using projected weekly usage + defense vs. position (DVP placeholder), compute weeks where player is likely startable.
	‚Ä¢	Return startable_weeks and early_season_value (Weeks 1-4 emphasis).

5) Exposure Control (Nice-to-Have #3)
	‚Ä¢	Track user‚Äôs players across multiple drafts (user_id scope).
	‚Ä¢	Enforce soft caps (e.g., cap WR X at 20% exposure).
	‚Ä¢	During advice, flag ‚Äúoverexposed‚Äù and promote comparable alternatives.

6) Opponent Modeling (Nice-to-Have #4)
	‚Ä¢	Simple model: for each opponent team, predict next pick by combining roster needs + ADP + positional scarcity.
	‚Ä¢	Show ‚ÄúLikely to be taken before your next pick‚Äù badge.

‚∏ª

API Endpoints (implement)

GET /rankings?pos=&limit=&scoring_profile=
Returns merged projections + injuries + depth + ADP + VORP + tiers + MC summaries + schedule pockets.

POST /draft/pick
Body: { league_id, player_id, team_slot?, round, pick }
Marks player taken; updates caches and returns new best-available.

GET /advice?league_id=&round=&pick=&roster_state=
Returns { top5: [...], rationale: "...", fallbacks: [...] } including exposure and opponent modeling signals.

POST /sync/sleeper
Body: { league_id } ‚Äî fetches league settings, ADP, and live draft picks (if applicable).

GET /healthz
Returns { ok: true }.

‚∏ª

Frontend Pages
	‚Ä¢	/ ‚Äì overview, load league, configure scoring, see global ranks.
	‚Ä¢	/draft ‚Äì Live Draft Board:
	‚Ä¢	Columns: Available / Taken / Your Queue / Advice.
	‚Ä¢	Filters: position, tiers, ADP range, injury status, bye weeks, stacks.
	‚Ä¢	On-the-Clock strip: top 5 + one-tap toggles (Need WR / Avoid byes / Chase upside).
	‚Ä¢	Manual ‚ÄúAdd Pick‚Äù (type-ahead) for in-person drafts.

‚∏ª

Ingestion Jobs (APScheduler)
	‚Ä¢	Nightly: projections, depth charts, ADP (writes to DB).
	‚Ä¢	Every 5 min (in season/draft day): injuries/news.
	‚Ä¢	On demand: Sleeper league sync; one-shot populate last year stats.
	‚Ä¢	Provide seed scripts with synthetic CSVs to run without paid APIs.

‚∏ª

Definition of Done (Acceptance Criteria)
	1.	Rankings endpoint returns 250+ players enriched with: projections points, VORP, tiers, ADP, injury flags, depth rank, MC p10/p50/p90, startable weeks, exposure hints.
	2.	Draft tracking: marking a pick removes the player everywhere and recomputes advice < 300ms (cached).
	3.	Advice explains why (1-2 sentences) and shows 2 alternatives with clear trade-offs.
	4.	Opponent modeling highlights ‚â•3 players likely gone by your next pick (based on ADP + needs).
	5.	Exposure control: setting a cap updates advice (‚Äúoverexposed‚Äù badge) and suggests swaps.
	6.	Schedule pockets visible as a mini badge (‚ÄúStartable W1-3‚Äù) and sortable column.
	7.	Monte Carlo summaries render in UI (Floor/Ceiling chips) and drive a ‚ÄúChase upside‚Äù toggle.
	8.	E2E test: simulated 12-team draft flow passes; unit tests for scoring, VORP, advice, Monte Carlo pass.
	9.	One-command up via docker-compose up and migrate.sh/seed.sh.
	10.	CI runs lint + tests + builds containers on PR.

‚∏ª

Guided Build Checklist (have Copilot execute sequentially)

Phase 0 ‚Äî Project Init
	‚Ä¢	Create repo fantasy-assistant and scaffolding per Repo Layout.
	‚Ä¢	Add pyproject.toml and backend dependencies; add frontend package.json with Next.js + Tailwind.
	‚Ä¢	Add .env.example and NEVER commit real secrets.
	‚Ä¢	Configure docker-compose for api, frontend, db (Postgres), cache (Redis).
	‚Ä¢	Add GitHub Actions workflow ci.yml running:
	‚Ä¢	Backend: ruff, pytest
	‚Ä¢	Frontend: pnpm test + Playwright e2e (headless)

Phase 1 ‚Äî DB & Models
	‚Ä¢	Implement 001_init.sql; write migrate.sh to apply migrations.
	‚Ä¢	Create SQLAlchemy models mirroring tables; init async engine + session in db/base.py.
	‚Ä¢	Implement services/id_map.py to normalize player IDs across sources (sleeper_id, gsis_id, espn_id, pfr_id).

Phase 2 ‚Äî Scoring + VORP + Tiers
	‚Ä¢	Implement core/scoring.py with a pure function taking stats + scoring JSON.
	‚Ä¢	Implement core/vorp.py with positional baselines and z-score tiers (natural gap heuristic).
	‚Ä¢	Unit tests: test_scoring.py, test_vorp.py with fixtures.

Phase 3 ‚Äî Ingestion (seed + real)
	‚Ä¢	Add seed.sh and example CSVs to populate: players, historical_stats, projections, depth_charts, injuries, adp.
	‚Ä¢	Implement services/ingest_* modules to load CSVs and (behind flags) call real APIs if keys are present.
	‚Ä¢	Implement workers/scheduler.py with APScheduler jobs and logging.

Phase 4 ‚Äî Core Endpoints
	‚Ä¢	/rankings: join projections + injuries + depth + ADP ‚Üí compute points, VORP, tiers.
	‚Ä¢	/draft/pick: accept a pick, write DB, update Redis sets for ‚Äúavailable‚Äù vs ‚Äútaken‚Äù.
	‚Ä¢	/advice: compute top 5 considering roster needs, ADP drift, stacks, depth, injuries, bye weeks.
	‚Ä¢	Add lightweight LLM rationale function (stub: returns templated rationale when LLM_API_KEY empty).

Phase 5 ‚Äî The Four Nice-to-Haves
	‚Ä¢	core/monte_carlo.py: simulate N=5,000 seasons per player; return p10/p50/p90 and volatility.
	‚Ä¢	core/schedule_pockets.py: compute startable weeks using weekly usage assumptions + DVP placeholder.
	‚Ä¢	core/exposure.py: track picks across user_id scope; enforce caps; add flags in /advice.
	‚Ä¢	core/opponent_model.py: predict opponent picks (ADP + needs); surface ‚Äúlikely gone‚Äù list.

Phase 6 ‚Äî Frontend
	‚Ä¢	Build / with global ranks, filters (position, tiers, injury, bye, ADP, upside toggle).
	‚Ä¢	Build /draft with Live Board, On-the-Clock strip, Queue, Advice panel.
	‚Ä¢	Add manual ‚ÄúAdd Pick‚Äù input; wire to /draft/pick; optimistic UI update.
	‚Ä¢	Add chips for Floor/Ceiling, Startable Weeks, Exposure, Likely Gone.

Phase 7 ‚Äî Tests & CI
	‚Ä¢	Write unit tests for advice, Monte Carlo, schedule pockets, exposure, opponent model.
	‚Ä¢	Write Playwright e2e: simulate picks and assert the UI updates + advice changes.
	‚Ä¢	Ensure CI green; add code coverage badge.

Phase 8 ‚Äî DX & Ops
	‚Ä¢	Make docker-compose up run API at :8000, Frontend at :3000.
	‚Ä¢	migrate.sh & seed.sh work in containers.
	‚Ä¢	Add README.md with quickstart and screenshots.

‚∏ª

Commands Copilot Should Run (scripts)

Backend (pyproject):

[tool.ruff]
target-version = "py312"

[tool.pytest.ini_options]
pythonpath = ["app"]
addopts = "-q"

package.json (frontend) scripts:

{
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "test": "playwright test"
  }
}

docker-compose (ops/docker-compose.yml) targets:
	‚Ä¢	api builds from /backend/Dockerfile, exposes 8000, depends on db, cache.
	‚Ä¢	frontend builds from /frontend/Dockerfile, exposes 3000, depends on api.
	‚Ä¢	db uses postgres:16-alpine with volume.
	‚Ä¢	cache uses redis:7-alpine.

‚∏ª

PR Plan (have Copilot follow this)
	1.	Create branch feat/scaffold.
	2.	Commit repo layout, Docker, CI; open PR ‚ÄúScaffold: API+UI+Ops‚Äù.
	3.	Create branch feat/core-ranking ‚Üí implement scoring/VORP/tiers + tests ‚Üí PR.
	4.	Create branch feat/ingestion ‚Üí seed + jobs ‚Üí PR.
	5.	Create branch feat/advice ‚Üí advice endpoint + roster logic ‚Üí PR.
	6.	Create branch feat/nh1-monte-carlo ‚Üí PR.
	7.	Create branch feat/nh2-schedule-pockets ‚Üí PR.
	8.	Create branch feat/nh3-exposure ‚Üí PR.
	9.	Create branch feat/nh4-opponent-model ‚Üí PR.
	10.	Create branch feat/frontend ‚Üí UI + e2e ‚Üí PR.
	11.	Final branch chore/polish ‚Üí docs, screenshots, perf, rate limits ‚Üí PR.

‚∏ª

Review Checklist (tick before merge)
	‚Ä¢	Rankings stable and sort correctly by VORP then FP.
	‚Ä¢	Advice returns in <300ms with Redis hot cache.
	‚Ä¢	MC outputs (p10/p50/p90) visible and used when ‚ÄúChase Upside‚Äù is on.
	‚Ä¢	Startable weeks chips render; sortable column works.
	‚Ä¢	Exposure caps enforce suggestions; badge appears when exceeded.
	‚Ä¢	Opponent model marks at least 3 ‚Äúlikely gone‚Äù players correctly on test data.
	‚Ä¢	All tests pass locally and in CI; containers build without warnings.

‚∏ª

Notes for Copilot
	‚Ä¢	Prefer pure functions in core/ with unit tests.
	‚Ä¢	Keep projection sources abstracted behind services/ with a CSV fallback so the app runs without paid keys.
	‚Ä¢	Don‚Äôt scrape; use provided seed data structure and stubs for real API calls.
	‚Ä¢	Favor type hints, docstrings, and small modules.

‚∏ª
